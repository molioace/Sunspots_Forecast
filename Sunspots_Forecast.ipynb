{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLl52leVp5wU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDrgVqCTao9j"
      },
      "outputs": [],
      "source": [
        "def plot_series(x, y, format=\"-\", start=0, end=None, title=None, xlabel=None, ylabel=None, legend=None ):\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    if type(y) is tuple:\n",
        "      for y_curr in y:\n",
        "        plt.plot(x[start:end], y_curr[start:end], format)\n",
        "\n",
        "    else:\n",
        "      plt.plot(x[start:end], y[start:end], format)\n",
        "\n",
        "    plt.xlabel(xlabel)\n",
        "\n",
        "    plt.ylabel(ylabel)\n",
        "\n",
        "    if legend:\n",
        "      plt.legend(legend)\n",
        "\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miE0cEqdu3eS"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/tensorflow-1-public/course4/Sunspots.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcG9r1eClbTh"
      },
      "outputs": [],
      "source": [
        "time_step = []\n",
        "sunspots = []\n",
        "\n",
        "with open('./Sunspots.csv') as csvfile:\n",
        "\n",
        "  reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "  next(reader)\n",
        "\n",
        "  for row in reader:\n",
        "    time_step.append(int(row[0]))\n",
        "    sunspots.append(float(row[2]))\n",
        "\n",
        "time = np.array(time_step)\n",
        "series = np.array(sunspots)\n",
        "\n",
        "plot_series(time, series, xlabel='Month', ylabel='Monthly Mean Total Sunspot Number')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L92YRw_IpCFG"
      },
      "outputs": [],
      "source": [
        "split_time = 3000\n",
        "\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJwUUZscnG38"
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z0qRGp1zl5b"
      },
      "outputs": [],
      "source": [
        "window_size = 30\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n",
        "\n",
        "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6kJd40-0Hj9"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=3,strides=1,\n",
        "                           activation=\"relu\",padding='causal',input_shape=[window_size, 1]),\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpVZbobXM117"
      },
      "outputs": [],
      "source": [
        "init_weights = model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AclfYY3Mn6Ph"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
        "\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVcKmg7Q_7rD"
      },
      "outputs": [],
      "source": [
        "lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\n",
        "\n",
        "plt.tick_params('both', length=10, width=1, which='both')\n",
        "\n",
        "plt.axis([1e-8, 1e-3, 0, 100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsksvkcXAAgq"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model.set_weights(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBYFogmdFM-R"
      },
      "outputs": [],
      "source": [
        "\n",
        "learning_rate = 5e-6\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrcqLyLALmCY"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_set,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD2kyYUVt3O0"
      },
      "outputs": [],
      "source": [
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "epochs=range(len(loss))\n",
        "\n",
        "plot_series(\n",
        "    x=epochs,\n",
        "    y=(mae, loss),\n",
        "    title='MAE and Loss',\n",
        "    xlabel='MAE',\n",
        "    ylabel='Loss',\n",
        "    legend=['MAE', 'Loss']\n",
        "    )\n",
        "\n",
        "zoom_split = int(epochs[-1] * 0.2)\n",
        "epochs_zoom = epochs[zoom_split:]\n",
        "mae_zoom = mae[zoom_split:]\n",
        "loss_zoom = loss[zoom_split:]\n",
        "\n",
        "plot_series(\n",
        "    x=epochs_zoom,\n",
        "    y=(mae_zoom, loss_zoom),\n",
        "    title='MAE and Loss',\n",
        "    xlabel='MAE',\n",
        "    ylabel='Loss',\n",
        "    legend=['MAE', 'Loss']\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XwGrf-A_wF0"
      },
      "outputs": [],
      "source": [
        "def model_forecast(model, series, window_size, batch_size):\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
        "\n",
        "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
        "\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    forecast = model.predict(dataset)\n",
        "\n",
        "    return forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5f7kKbFL6zv"
      },
      "outputs": [],
      "source": [
        "forecast_series = series[split_time-window_size:-1]\n",
        "\n",
        "forecast = model_forecast(model, forecast_series, window_size, batch_size)\n",
        "\n",
        "results = forecast.squeeze()\n",
        "\n",
        "plot_series(time_valid, (x_valid, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jZrRYjQMNHr"
      },
      "outputs": [],
      "source": [
        "mae_metric = tf.keras.metrics.MeanAbsoluteError()\n",
        "mae_metric.update_state(x_valid, results)\n",
        "mae = mae_metric.result().numpy()\n",
        "print(mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRSiHiPXg9BQ"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-7, momentum=0.9)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "history = model.fit(train_set,epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v9hyAmUov66"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate=1e-7\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=400,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "history = model.fit(train_set,epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Syj7stJSQkV0"
      },
      "outputs": [],
      "source": [
        "forecast_series = series[split_time-window_size:-1]\n",
        "\n",
        "forecast = model_forecast(model, forecast_series, window_size, batch_size)\n",
        "\n",
        "results = forecast.squeeze()\n",
        "\n",
        "plot_series(time_valid, (x_valid, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPjq8diYQluc"
      },
      "outputs": [],
      "source": [
        "mae_metric = tf.keras.metrics.MeanAbsoluteError()\n",
        "mae_metric.update_state(x_valid, results)\n",
        "mae = mae_metric.result().numpy()\n",
        "print(mae)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}